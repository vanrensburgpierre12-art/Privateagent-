version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_URL=${OLLAMA_URL:-http://host.docker.internal:11535}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama-3.2-70b}
      - CHROMA_PERSIST_DIR=/app/chroma_persist
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      - MAX_CONTEXT_TOKENS=${MAX_CONTEXT_TOKENS:-4000}
      - CHUNK_SIZE=${CHUNK_SIZE:-500}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-50}
      - CORS_ORIGINS=http://localhost:5173,http://localhost:3000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./data/chroma:/app/chroma_persist
    depends_on:
      - frontend
    networks:
      - app-network

  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://localhost:8000
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  chroma_data:
    driver: local